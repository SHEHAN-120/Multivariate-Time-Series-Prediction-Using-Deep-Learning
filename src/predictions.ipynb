{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e87e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb887085",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "src_path = os.path.join(current_dir, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49bcc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in d:\\project\\ai\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in d:\\project\\ai\\lib\\site-packages (from import-ipynb) (8.37.0)\n",
      "Requirement already satisfied: nbformat in d:\\project\\ai\\lib\\site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: colorama in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (2.19.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: decorator in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (4.15.0)\n",
      "Requirement already satisfied: stack_data in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (0.6.3)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: exceptiongroup in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (1.3.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (3.0.52)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\project\\ai\\lib\\site-packages (from IPython->import-ipynb) (0.2.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\project\\ai\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.5)\n",
      "Requirement already satisfied: wcwidth in d:\\project\\ai\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.14)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\project\\ai\\lib\\site-packages (from nbformat->import-ipynb) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\project\\ai\\lib\\site-packages (from nbformat->import-ipynb) (4.25.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\project\\ai\\lib\\site-packages (from nbformat->import-ipynb) (5.9.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\project\\ai\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.9.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\project\\ai\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.4.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\project\\ai\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.29.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\project\\ai\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.37.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\project\\ai\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.5.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\project\\ai\\lib\\site-packages (from stack_data->IPython->import-ipynb) (3.0.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\project\\ai\\lib\\site-packages (from stack_data->IPython->import-ipynb) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in d:\\project\\ai\\lib\\site-packages (from stack_data->IPython->import-ipynb) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.3 is available.\n",
      "You should consider upgrading via the 'D:\\Project\\ai\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70611d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "\n",
    "import ab\n",
    "import data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27bfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for model at: d:\\Project\\src\\models/trained_model.h5\n",
      "model and scaler\n",
      "Reading data from d:\\Project\\src\\../data/raw/energy_data_set.csv...\n",
      "Scaling data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "\n",
      "========================================\n",
      "PREDICTION RESULT\n",
      "Predicted Consumption: 296.44 Wh\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_next_hour(input_csv_path):\n",
    "    \n",
    "    BASE_DIR = os.getcwd()\n",
    "    MODEL_PATH = os.path.join(BASE_DIR, 'models/trained_model.h5')\n",
    "    SCALER_PATH = os.path.join(BASE_DIR, 'models/scaler.pkl')\n",
    "    \n",
    "    print(f\"Looking for model at: {MODEL_PATH}\")\n",
    "    if not os.path.exists(MODEL_PATH) or not os.path.exists(SCALER_PATH):\n",
    "        print(\"Model or Scaler not found.\") \n",
    "        return\n",
    "\n",
    "    print(\"model and scaler\")\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "    \n",
    "    scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "    \n",
    "    print(f\"Reading data from {input_csv_path}...\")\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    \n",
    "    df = ab.feature_engineering_pipeline(df)\n",
    "    \n",
    "    \n",
    "    cols_to_drop = ['date', 'day_of_week', 'cluster', 'outlier_flag', 'rv1', 'rv2']\n",
    "    features = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "    \n",
    "    print(\"Scaling data\")\n",
    "    scaled_array = scaler.transform(features)\n",
    "    \n",
    "    \n",
    "    WINDOW_SIZE = 24\n",
    "    if len(scaled_array) < WINDOW_SIZE:\n",
    "        print(f\"Not enough data! Need at least {WINDOW_SIZE} rows.\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    last_sequence = scaled_array[-WINDOW_SIZE:] \n",
    "    input_batch = last_sequence.reshape((1, WINDOW_SIZE, last_sequence.shape[1]))\n",
    "\n",
    "    \n",
    "    print(\"Predicting\")\n",
    "    \n",
    "    prediction_scaled = model.predict(input_batch)\n",
    "    pred_value_scaled = prediction_scaled[0][0]\n",
    "\n",
    "    \n",
    "    target_col_name = 'Appliances'\n",
    "    try:\n",
    "        target_idx = list(features.columns).index(target_col_name)\n",
    "    except ValueError:\n",
    "        print(\"Target column not found.\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    data_min = scaler.data_min_[target_idx]\n",
    "    data_range = scaler.data_range_[target_idx]\n",
    "    \n",
    "    predicted_energy = (pred_value_scaled * data_range) + data_min\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"PREDICTION RESULT\")\n",
    "    print(f\"Predicted Consumption: {predicted_energy:.2f} Wh\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "    \n",
    "    return predicted_energy\n",
    "\n",
    "test_file = os.path.join(os.getcwd(), '../data/raw/energy_data_set.csv')\n",
    "\n",
    "prediction = predict_next_hour(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b2571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
